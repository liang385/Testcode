1： 核心配置文件-core-site.xml

<configuration>
 <!-- 指定 NameNode 的地址 -->
 <property>
 <name>fs.defaultFS</name>
 <value>hdfs://nameNode:8020</value>
 </property>
 <!-- 指定 hadoop 数据的存储目录 -->
 <property>
 <name>hadoop.tmp.dir</name>
 <value>/opt/module/hadoop/data</value>
 </property>
 <!-- 配置 HDFS 网页登录使用的静态用户为 root-->
 <property>
 <name>hadoop.http.staticuser.user</name>
 <value>root</value>
 </property>
</configuration>

2：HDFS 配置文件-hdfs-site.xml

<configuration>
<!-- nn web 端访问地址-->
<property>
 <name>dfs.namenode.http-address</name>
 <value>hadoop102:9870</value>
 </property>
<!-- 2nn web 端访问地址-->
 <property>
 <name>dfs.namenode.secondary.http-address</name>
 <value>hadoop104:9868</value>
 </property>
<!--设置HDFS文件副本数-->
<property>
 <name>dfs.replication</name>
 <value>1</value>
 </property>
<!--设置其他用户执行操作时会提醒没有权限的问题-->
<property>
 <name>dfs.permissions</name>
 <value>false</value>
 </property>


</configuration>

3：YARN 配置文件-yarn-site.xml

<configuration>
 <!-- 指定 MR 走 shuffle -->
 <property>
 <name>yarn.nodemanager.aux-services</name>
 <value>mapreduce_shuffle</value>
 </property>
 <!-- 指定 ResourceManager 的地址-->
 <property>
 <name>yarn.resourcemanager.hostname</name>
 <value>hadoop103</value>
 </property>
 
</configuration>

4：MapReduce 配置文件 mapred-site.xml

<configuration>
<!-- 指定 MapReduce 程序运行在 Yarn 上 -->
 <property>
 <name>mapreduce.framework.name</name>
 <value>yarn</value>
 </property>
</configuration>

5:配置hadoop环境的配置文件hadoop-env.sh

export JAVA_HOME=/app/jdk

6:从节点配置文件slaves
hadoop000

7:格式化HDFS系统
hadoop namenode -format

